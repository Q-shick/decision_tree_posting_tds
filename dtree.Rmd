---
title: "Decision Tree"
output: html_document
---

This R code is written for the posting "Decision Tree for Better Usage". It examines the following cases.
- Overfitting: Evaluated against training set
- Parameter Tweak: Limiting max depth
- Bagging: Random Forest
Some chunks have a random seed set. Such numbers are chosen that the expecting results are produced for educational purpose.

```{r warning=FALSE, message=FALSE}
library(rpart) # decision tree
library(rpart.plot) # plotting decision tree
library(randomForest) # random forest

set.seed(2019)
```

```{r}
# Read the dataset
loans <- read.csv('loans.csv', na.strings = c("", "NA"))
loans <- loans[complete.cases(loans), ]

# Down sample
loans <- downSample(loans, loans$Loan_Status)
loans <- subset(loans, select = -c(Loan_ID, Class))
```

```{r}
# 1/3 for testing set
split <- sample.split(loans$Loan_Status, SplitRatio = 2/3)
training.set <- subset(loans, split == T)
testing.set <- subset(loans, split == F)
```

```{r}
# Build a classification model
clf <- rpart(formula = Loan_Status ~., data = training.set,
             control = rpart.control(minsplit = 1))

# Predict from new data
pred <- predict(clf, newdata = training.set[, -12], type = 'class')

# Check the accuracy
round(sum(training.set[, 12]==pred)/length(pred), 2)

rpart.plot(clf, box.palette = 'RdBu', nn = T)
# prp(clf, box.palette = 'RdBu', tweak = 1.5)
```

```{r}
clf <- rpart(formula = Loan_Status ~., data = training.set,
             control = rpart.control(minsplit = 1))
pred <- predict(clf, newdata = testing.set[, -12], type = 'class')
round(sum(testing.set[, 12]==pred)/length(pred), 2)
```


```{r}
# Set maxdepth to 3
clf <- rpart(formula = Loan_Status ~., data = training.set,
             control = rpart.control(minsplit = 1, maxdepth = 3))

# Evaluate against testing set
pred <- predict(clf, newdata = testing.set[-12], type = 'class')

# Accuracy against new data
round(sum(testing.set[, 12]==pred)/length(pred), 2)

rpart.plot(clf, box.palette = 'RdBu', nn = T)
```


```{r}
set.seed(1234)

# Build 100 trees with max node
clf <- randomForest(x = training.set[-12],
                    y = training.set$Loan_Status,
                    ntree = 100, maxnodes = 5)

pred <- predict(clf, newdata = testing.set[-12], type = 'class')
round(sum(testing.set[, 12]==pred)/length(pred), 2)

round(importance(clf))
```